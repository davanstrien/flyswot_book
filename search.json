[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "How we built a Pragmatic Machine Learning Pipeline to Identify Fake Flysheets as part of a Library Workflow",
    "section": "",
    "text": "In 1979, two Swedish bands released albums. One of these albums, Voulez-Vous, was recorded by ABBA in Polar Studios, at its time, one of the most advanced — and expensive — recording studios in the world. The other album, We're Only in it for the Drugs, by the Swedish Punk band Ebba Grön was recorded on a mobile 8-channel mixer in a closed industrial office. Both these albums are great, but the resources available to create them were vastly different.\nThere is a prevalent perception that machine learning is only for those with deep pockets. For example, in 2022, Google created a new Language Model, PaLM, but the cost of training such a model is estimated to be between $9M to $23M. As a result, discussions of machine learning often focus on large tech companies because they are deemed to be the only ones with the finances to develop and use this technology.\nMachine learning, and in particular a branch of machine learning called deep learning, has dramatically impacted a range of domains over the past ten years. There has been a growing interest in using machine learning in gallery, library, archive and museum (GLAM) institutions. A barrier to further adoption of machine learning in the GLAM sector is the perception that it requires extensive technical skill, data, computing power and other resources.\nIn this book, we want to show that just as Ebba Grön was able to record a seminal album without the resources available to ABBA, GLAM institutions can use machine learning for practical work without the resources of Google."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "The growing interest in using Artificial Intelligence/Machine Learning in a GLAM setting is demonstrated by the many initiatives and groups aiming to develop communities and best practices around applying AI/Machine Learning in GLAM settings. These initiatives include; ai4lam and CENEL's AI in Libraries Network Group.\nThere are also several funded projects which seek to explore this area, including the AEOLIAN Network, Unlocking our Digital Past and the AURA Network.\nThese more academic projects can produce a range of resources that can be helpful for GLAM institutions wanting to use machine learning. These primarily include publications, code, and, to a lesser extent, datasets. Whilst these projects are essential as part of the development of machine learning within the sector, there are potential limitations to these projects being the sole method of building capacity for machine learning projects within the GLAM community.\nThere is also a growing body of materials focused on teaching GLAM staff topics related to machine learning. A review of some of this material has been carried out by the Teaching and Learning working group of the AI4LAM network Darby et al. (2022).\nThis material includes general introductions to machine learning for GLAM staff van Strien et al. (2022), practical introductions to using the Python programming language for machine learning 1 and introductions to a specific tool. 2\nWhile this more ‘formal’ teaching material is an essential part of enabling GLAM staff to engage with machine learning, there are limitations to relying only on this material. These materials often need to focus on a particular topic, concept or approach within machine learning, for example, an introduction to Named Entity Recognition. However, learning how to train a machine learning model, or use an existing model, is only one part of a more extensive pipeline for practically making use of machine learning in a GLAM setting."
  },
  {
    "objectID": "intro.html#whats-covered",
    "href": "intro.html#whats-covered",
    "title": "2  Introduction",
    "section": "2.1 What's covered",
    "text": "2.1 What's covered\nThe book covers a few key areas:\n\nthe motivation of the project\nthe various stages in the pipeline:\n\ndata collection\ndata versioning\nmodel development\nmodel evaluation\ntracking results\ndeployment\nupdating the model\n\n\nAll of these are discussed with a particular focus on how they fit into existing workflows and how they can be done pragmatically."
  },
  {
    "objectID": "intro.html#what-isnt-covered",
    "href": "intro.html#what-isnt-covered",
    "title": "2  Introduction",
    "section": "2.2 What isn't covered",
    "text": "2.2 What isn't covered\nThis isn't a guide on how to do machine learning itself. Although some of the sections touch upon some of these considerations, this book won't explain everything thoroughly. If you want a more conceptual introduction to machine learning, we recommend https://carpentries-incubator.github.io/machine-learning-librarians-archivists. For a hands-on introduction, we recommended https://course.fast.ai/."
  },
  {
    "objectID": "intro.html#who-is-this-for",
    "href": "intro.html#who-is-this-for",
    "title": "2  Introduction",
    "section": "2.3 Who is this for?",
    "text": "2.3 Who is this for?\nWe hope that this book will be useful for other GLAM institutions wanting to embark on machine learning projects. In particular, we are keen to address ‘business as usual’ use cases of machine learning in GLAM institutions as we believe there is massive scope for using machine learning methods across a range of ‘mundane’ GLAM activities."
  },
  {
    "objectID": "intro.html#practical-machine-learning-projects",
    "href": "intro.html#practical-machine-learning-projects",
    "title": "2  Introduction",
    "section": "2.4 Practical machine learning projects?",
    "text": "2.4 Practical machine learning projects?\nA report has suggested that 85% of AI projects “ultimately fail to deliver on their intended promises to business”5. This stat might be a little dubious, but there is some truth to the claim that machine learning projects can be challenging. By a “machine learning project,” we mean a project that intends to use machine learning to solve a problem. Part of this process could include creating new machine learning models, but it could also rely on existing models.\nWe use the term “practical” here to try and distinguish this type of project slightly from other projects which may involve using machine learning in a GLAM setting but are more focused on research. The outputs of these projects may need to integrate less tightly into existing business workflows and processes. This isn’t to say that these kinds of projects won’t have their own challenges, but they will likely be different. ‘Practical’ machine learning projects could include workflows and processes that end users don’t see and are likely to be the kinds of projects that may struggle to get external funding.\n\n\n\n\nAmeisen, Emmanuel. 2020. Building Machine Learning Powered Applications: Going from Idea to Product. \" O’Reilly Media, Inc.\".\n\n\nDarby, Andrew, Catherine Nicole Coleman, Claudia Engel, Daniel Alexander van Strien, Michael Trizna, and Zachary Painter. 2022. “AI Training Resources for GLAM: A Snapshot.” ArXiv abs/2205.04738.\n\n\nHuyen, Chip. 2022. Designing Machine Learning Systems. \" O’Reilly Media, Inc.\".\n\n\nLakshmanan, Valliappa, Sara Robinson, and Michael Munn. 2020. Machine Learning Design Patterns. O’Reilly Media.\n\n\nvan Strien, Daniel, Mark Bell, Nora Rose McGregor, and Michael Trizna. 2022. “An Introduction to AI for GLAM.” In Proceedings of the Second Teaching Machine Learning and Artificial Intelligence Workshop, edited by Katherine M. Kinnaird, Peter Steinbach, and Oliver Guhr, 170:20–24. Proceedings of Machine Learning Research. PMLR. https://proceedings.mlr.press/v170/strien22a.html."
  },
  {
    "objectID": "business_problem.html",
    "href": "business_problem.html",
    "title": "3  Defining the ‘business problem’",
    "section": "",
    "text": "One of the first things we may want to do when doing an machine learning project is to ensure we have defined what we are trying to achieve. Often this can be framed around a ‘business problem’. We put both of these in scare quotes because if we work in a GLAM institution we may not consider ourselves a ‘business’. We may also not be tackling a ‘problem’ as much as we’re hoping to machine learning to do something new. However, being clear about what the outcome is may be particularly important when we’re trying to use machine learning for more practical tasks.\nIf our goal is to produce a paper or do some exploraty assesment of what machine learning may enable us to do we may have more vague sucess criteria. We may, for example, be happy to apply some pre-trained models to some of our data and asess the performance of that model on our data. This asssment may be done manually i.e. look at a few example results some ‘off-the-shelf’ machine learning models produce for our data. It could also be a more robust assesment of model performance on an evaluation dataset. For example, we may apply a Named entity Recognitoin model to some data we’ve annotated and see how well the model performs.\nWe’ll come back to assessing our model performance in more detail later. However, in order to know what performance is acceptable we need to have a good grasp of what our actual business problem is – what is the things we’re trying to achieve and how does this fit into existing or new workflows? If this is ill-defined it will be difficult to later on assess whether we’ve been sucesful or not."
  },
  {
    "objectID": "business_problem.html#defining-the-business-problem-for-hertiage-made-digital",
    "href": "business_problem.html#defining-the-business-problem-for-hertiage-made-digital",
    "title": "3  Defining the ‘business problem’",
    "section": "3.1 Defining the ‘business’ problem for Hertiage Made Digital",
    "text": "3.1 Defining the ‘business’ problem for Hertiage Made Digital\nThe British Library has a vast amount of ‘legacy’ digitised content stored on network drives. The Heritage Made Digital (HMD) team has been tasked with making these available for users online. We have multiple terabytes of image files, mostly containing photos or scans of the items in our physical collection. One of the viewing platforms that we have made our manuscript image sets available on over the years is our Digitised Manuscripts (DM) website so that people can look at and study the digitised versions of the physical objects without needing to come into one of our buildings in St Pancras or Boston Spa.\nThe thing is, DM was never designed to be our primary, strategic, good-for-all-occasions image viewer. It was built for a specific project that wanted to publish a limited number of similarly constructed manuscripts. Namely the Greek Manuscripts project.\n\n\n\n\n\n\n\n(a) Digitsed manuscript platform\n\n\n\n\nFigure 3.1: Digitised manuscripts platform for 1784.a.13.1\n\n\nThe physical structure of the items in the Greek Manuscripts project are largely uniform. They are bound codices (of varying sizes and material types) and to digitise these all you need to do is take a photo of the front cover, front flysheets, folios, end flysheets, back cover and spine. That’s six different types of images. Or, in terms of our standardised filenames (ignoring the r and v we put at the end of filenames for each recto and verso shot, for the sake of simplicity):\n\nfblef - front cover\nfs001 - front flysheet\nf001 - folio\nfse001 - end flysheet\nfbrig - back cover\nfbspi - spine\n\nAnd so DM was built to accommodate these and only these options, with no room for something physically unusual that didn’t fit this standard.\nRegardless of this shortcoming, DM was pretty good, and better than anything else we had at the time, so other projects started using it to publish their manuscript material. This is where the problem arose.\nThe material in these other projects wasn’t as uniform as the items in the Greek Manuscripts project, and sometimes we wanted to take images of fore-edges, or clasps, or bags, or anything else interesting or integral to the physical item. The only way to publish these images on DM was to assign them one of the six standard filenames, and the agreed approach was to call them an end flysheet, and give it a number at the end of the sequence. In other words, if you already have two end flysheets, the image filename of the fore-edge will be called fse003. A ‘fake’ flysheet.\nThis worked fine for years, but we are now at the point of moving on from Digitised Manuscripts and we are beginning to migrate all our digital content into our new preservation and access system, allowing people to view and download images from our IIIF-compatible viewer, the Universal Viewer.\nThis new system allows us to display whatever images we want, in any sequence order, and label them however we want, regardless of the filename. This gives us an opportunity to correctly relabel images that were published to DM as ‘fake’ flysheets, so that users can better understand the digital objects we’re presenting to them.\n\n\n\n\n\n\n\n(a) Digitsed manuscript platform showing page types being derived from the filename\n\n\n\n\nFigure 3.2: Digitised manuscripts platform with pages types\n\n\nUnfortunately, however, we kept little to no records of which images we renamed as ‘fake’ flysheets. There are potentially hundreds or thousands of these scattered throughout the tens of thousands of items we’ve digitised. Rather than manually checking every image as we migrate it to the new system we thought it might be more efficient and sustainable to use an automated or semi-automated computational method to do this task, or at least get one to help us to do it.\nIt’s worth saying that even though we may have initially dreamed of a magic program to solve all our problems - identifying all our ‘fake’ flysheets with a click of a button and relabelling them for us - we very quickly downgraded our expectations. The main reason we couldn’t put our faith in a totally automated solution is because we know our collection (or at least we know how physically varied it can be), how big it is, and how we don’t really know everything about it. Given the myriad of items we’ve digitised over the last 20+ years, we were pretty sure a tool wouldn’t be able to pick out all the subtle differences in images with 100% accuracy - a task even trained humans find difficult to do. This turned out to be a fairly sensible assumption and what we actually needed was a tool that could be used as part of our existing migration workflow, confirming the large majority of images as real flysheets whilst flagging up images it suspected were fakes, for a human to then manually confirm or deny by looking at the image.\nSo the task became one to create a tool as quickly and easily as possible, that was simple to use and maintain, that fit into our existing workflow, gave us accurate results, and we felt confident enough to trust. Because we lacked the required software development skills within the team, we turned to colleagues with expertise in machine learning and set up a meeting to outline our requirements; so the concept for flyswot was born.\nA bonus to this whole approach was that we could work more closely with colleagues we don’t necessarily engage with on a day-to-day basis. It also brought a subset of our team closer together in pursuit of a new extracurricular activity, and we’d all be able to learn about new tools and technologies."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ameisen, Emmanuel. 2020. Building Machine Learning Powered\nApplications: Going from Idea to Product. \" O’Reilly Media, Inc.\".\n\n\nDarby, Andrew, Catherine Nicole Coleman, Claudia Engel, Daniel Alexander\nvan Strien, Michael Trizna, and Zachary Painter. 2022. “AI\nTraining Resources for GLAM: A Snapshot.” ArXiv\nabs/2205.04738.\n\n\nHuyen, Chip. 2022. Designing Machine Learning Systems. \"\nO’Reilly Media, Inc.\".\n\n\nLakshmanan, Valliappa, Sara Robinson, and Michael Munn. 2020.\nMachine Learning Design Patterns. O’Reilly Media.\n\n\nvan Strien, Daniel, Mark Bell, Nora Rose McGregor, and Michael Trizna.\n2022. “An Introduction to AI for GLAM.” In Proceedings\nof the Second Teaching Machine Learning and Artificial Intelligence\nWorkshop, edited by Katherine M. Kinnaird, Peter Steinbach, and\nOliver Guhr, 170:20–24. Proceedings of Machine Learning Research. PMLR.\nhttps://proceedings.mlr.press/v170/strien22a.html."
  }
]
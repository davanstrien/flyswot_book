<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>How we built a Pragmatic Machine Learning Pipeline to Identify Fake Flysheets as part of a Library Workflow - 4&nbsp; Creating training data: annotation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./business_problem.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<meta name="twitter:title" content="How we built a Pragmatic Machine Learning Pipeline to Identify Fake Flysheets as part of a Library Workflow - 4&nbsp; Creating training data: annotation">
<meta name="twitter:description" content="When developing our project we used a supervised machine-learning approach.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating training data: annotation</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">How we built a Pragmatic Machine Learning Pipeline to Identify Fake Flysheets as part of a Library Workflow</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./business_problem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching ML projects: defining the ‚Äòproblem‚Äô</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./creating-training-data.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating training data: annotation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#how-did-we-create-training-data-who-does-the-annotation" id="toc-how-did-we-create-training-data-who-does-the-annotation" class="nav-link active" data-scroll-target="#how-did-we-create-training-data-who-does-the-annotation"><span class="toc-section-number">4.0.1</span>  How did we create training data: who does the annotation?</a></li>
  <li><a href="#crowdworkers" id="toc-crowdworkers" class="nav-link" data-scroll-target="#crowdworkers"><span class="toc-section-number">4.0.2</span>  Crowdworkers üí™</a></li>
  <li><a href="#crowdsource-via-volunteers" id="toc-crowdsource-via-volunteers" class="nav-link" data-scroll-target="#crowdsource-via-volunteers"><span class="toc-section-number">4.0.3</span>  Crowdsource via volunteers üíù</a></li>
  <li><a href="#diy" id="toc-diy" class="nav-link" data-scroll-target="#diy"><span class="toc-section-number">4.0.4</span>  DIY üõ†</a></li>
  <li><a href="#what-annotation-tool-did-we-use" id="toc-what-annotation-tool-did-we-use" class="nav-link" data-scroll-target="#what-annotation-tool-did-we-use"><span class="toc-section-number">4.1</span>  What annotation tool did we use?</a>
  <ul class="collapse">
  <li><a href="#why-did-we-use-this-approach" id="toc-why-did-we-use-this-approach" class="nav-link" data-scroll-target="#why-did-we-use-this-approach"><span class="toc-section-number">4.1.1</span>  Why did we use this approach?</a></li>
  <li><a href="#why-shouldnt-you-use-this-approach" id="toc-why-shouldnt-you-use-this-approach" class="nav-link" data-scroll-target="#why-shouldnt-you-use-this-approach"><span class="toc-section-number">4.1.2</span>  Why shouldn‚Äôt you use this approach?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Creating training data: annotation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>When developing our project we used a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine-learning</a> approach. This means that our model ‚Äúlearns‚Äù from seeing examples of input data; in this case, images and examples of the labels we want these images to have. In our particular example, this would mean the model has examples of ‚Äúfake‚Äù flysheets and real flysheets to learn to detect those incorrectly labeled.</p>
<section id="how-did-we-create-training-data-who-does-the-annotation" class="level3" data-number="4.0.1">
<h3 data-number="4.0.1" class="anchored" data-anchor-id="how-did-we-create-training-data-who-does-the-annotation"><span class="header-section-number">4.0.1</span> How did we create training data: who does the annotation?</h3>
<p>Generating training data is extremely important for supervised machine learning, but it is often given less attention than training or deploying models.</p>
<p>There are a few main broad options for generating annotated training data:</p>
<ul>
<li>Pay ‚Äúcrowdworkers‚Äù</li>
<li>Crowdsource it via volunteers</li>
<li>Do it yourself (DIY)</li>
</ul>
<p>We‚Äôll briefly discuss each option to explain what they mean but we'll mainly focus on discussing the option we chose.</p>
</section>
<section id="crowdworkers" class="level3" data-number="4.0.2">
<h3 data-number="4.0.2" class="anchored" data-anchor-id="crowdworkers"><span class="header-section-number">4.0.2</span> Crowdworkers üí™</h3>
<p>This refers to commercial services where people are employed (or more commonly paid a piece rate) for annotating data. Examples of this include the <a href="https://www.mturk.com/">Mechanical Turk</a> platform from Amazon, but many companies are offering some form of this service.</p>
<p>This type of service is likely not a common approach for GLAM institutions and wasn't relevant to this project. The cost and time spent on setting up this task would unlikely be worthwhile.</p>
</section>
<section id="crowdsource-via-volunteers" class="level3" data-number="4.0.3">
<h3 data-number="4.0.3" class="anchored" data-anchor-id="crowdsource-via-volunteers"><span class="header-section-number">4.0.3</span> Crowdsource via volunteers üíù</h3>
<p>Another potential option is to use crowdsourcing via volunteers. This is a well-established practice in GLAMs for generating collection data and allowing people to explore and contribute to research. There are also nice examples of crowdsourced data being used to train computer vision models, for example, the Newspaper Navigator project <span class="citation" data-cites="Lee2020TheNN">Lee et al. (<a href="references.html#ref-Lee2020TheNN" role="doc-biblioref">2020</a>)</span> used training data generated from <a href="https://labs.loc.gov/work/experiments/beyond-words/">Beyond Words</a> to train an object detection model for historic newspapers. Whilst this data wasn‚Äôt created for training machine learning models it was still possible to use the data for this purpose.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is growing interest in how machine learning and crowdsourcing can be combined and mutually benefit from each other. See, for example <a href="https://labs.loc.gov/work/experiments/humans-loop/?loclr=blogsig">Humans in the Loop</a> a crowdsourcing project from the Library of Congress.</p>
<p>This option wasn't considered seriously for this project for several reasons:</p>
<ul>
<li>there is overhead in designing and setting up crowdsourcing tasks that weren‚Äôt feasible for this particular project;</li>
<li>the amount of training data we needed was quite limited to start with, so it might not warrant the effort of setting up a crowdsourcing project;</li>
<li>we wanted to quickly develop a proof of concept using a small training dataset and develop from this starting point.</li>
</ul>
<p>Whilst this approach might work well in some situations, this should not be seen as an ‚Äòeasy‚Äô way of getting ‚Äòfree‚Äô training data. Since the process of creating training data often ends up as an iterative process it‚Äôs important to make sure you test the annotations you are producing can be used early on, ideally before asking volunteers to contribute.</p>
</div>
</div>
</section>
<section id="diy" class="level3" data-number="4.0.4">
<h3 data-number="4.0.4" class="anchored" data-anchor-id="diy"><span class="header-section-number">4.0.4</span> DIY üõ†</h3>
<p>A remaining option is for the team working on the project to produce the training data themselves. If you want to train a machine learning model on a task for which an open dataset does not exist, this is often a required first step. This is the option we ended up choosing. This is the most appropriate approach to developing new training data from the options available for ‚Äòproof of concept‚Äô applications of machine learning. Even if you are lucky enough to find an existing dataset for the task you want to do, you will likely still want to create some new data for testing your model's performance on your specific data.</p>
</section>
<section id="what-annotation-tool-did-we-use" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="what-annotation-tool-did-we-use"><span class="header-section-number">4.1</span> What annotation tool did we use?</h2>
<p>MicrosoftÔ∏è Windows File Explorer! More specifically, we create a folder for each label in our training data and add images that belong to that label so it looks something like this:</p>
<p><img src="assets/folder_structure_training_data.webp" class="img-fluid"></p>
<p>In our case, each image should belong to only one category e.g.&nbsp;<code>CONTAINER</code> so any images matching this category should go in this folder.</p>
<section id="why-did-we-use-this-approach" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="why-did-we-use-this-approach"><span class="header-section-number">4.1.1</span> Why did we use this approach?</h3>
<p>Organising data and the associated labels in this folder is a fairly standard way of distributing machine learning datasets. This format is supported in various downstream machine-learning frameworks.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>However, whilst this is often used as a ‚Äòdistribution‚Äô format, it is perhaps slightly unusual to use it to collect annotations. The reason we chose to use this approach:</p>
<ul>
<li>minimal setup costs (both in terms of time, effort and cost);</li>
<li>using folders to organise files is familiar to most people already;</li>
<li>it more closely fits into existing workflows.</li>
</ul>
<p>This final point is worth additional thought when trying to do a practical ML project within a GLAM setting. Annotating data can be time-consuming and, depending on the task, quite boring. Making annotation a brand new ‚Äòseparate‚Äô activity removes it from existing work and may lead to fewer people being able to contribute to this activity. In our particular situation, since members of the HMD team were already working through image files in preparation for ingest into their digital preservation store <a href="http://www.digitalpreservationsoftware.com/digital-preservation-solutions/libsafe-digital-preservation-software/"><em>L</em></a><a href="http://www.digitalpreservationsoftware.com/digital-preservation-solutions/libsafe-digital-preservation-software/"><em>ibSafe</em></a>, taking the extra step of putting any ‚Äòfake flysheet‚Äô they spotted into the ‚Äòtraining folder‚Äô wasn‚Äôt too far outside of their work process. If we had collected annotations through a more formal platform, the annotation process would be a separate activity, likely done through a web interface. Whilst this interface might be faster if the sole activity is doing annotations, a more informal approach may work better if the annotation process is to fit into an existing workflow.</p>
<p>How annotations are collected is an area of the ML pipeline where GLAMs may diverge from the more traditional workflows used in industry/commercial settings. The model of ‚Äòfarming out‚Äô annotating as a full-time activity will usually not be financially possible (and there might be other professional or ethical concerns about doing so). Beyond this, it might also not make sense to try and replicate a ‚Äòfull-time‚Äô annotation approach when the ML project has limited resources available. Instead, in these settings, thinking about how annotations could be collected more easily as part of a workflow might be sensible.</p>
</section>
<section id="why-shouldnt-you-use-this-approach" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="why-shouldnt-you-use-this-approach"><span class="header-section-number">4.1.2</span> Why shouldn‚Äôt you use this approach?</h3>
<p>There are limitations to this kind of approach that will make it unsuitable for some tasks. The first obvious limitation is that we can only annotate for performing classification using this approach, as the label for each image comes from the folder in which it sits. It could be a better approach for multi-label datasets, i.e.&nbsp;where each photo can have one, multiple or no associated labels. Beyond the tasks that this kind of approach can‚Äôt easily support, some other limitations include the following:</p>
<ul>
<li>minimal or no provenance information about who did the annotation, when it was done etc.</li>
<li>no easy way of managing annotations as ‚Äòtasks‚Äô for different team members</li>
<li>no easy way of generating inter-annotator agreement scores (measures of how much different people completing the annotations agree with each other).</li>
</ul>
<p>Most of these challenges stem from the fact that a file system isn‚Äôt intended for this kind of task. Although file systems usually record some information about changes to folders etc., this is not always very granular.</p>
<p>The final limitation of not being able to generate inter-annotator agreement scores are potentially very important for some projects. For example, a project aiming to apply metadata labels automatically to images or documents should carefully assess how much annotators agree with each other by getting multiple people to label the same item. If there is a lot of disagreement between annotators, then the labels might be ambiguous, or the task of giving the correct label might be a challenging one requiring expert knowledge. In these scenarios, it is worth the extra effort of setting up a proper annotation tool. Some options for these annotations platforms include:</p>
<ul>
<li><a href="http://labelstud.io/">Labelstudio</a></li>
<li><a href="https://github.com/wkentaro/labelme">Labelme</a></li>
<li><a href="https://prodi.gy/">Prodigy</a></li>
<li><a href="https://github.com/openvinotoolkit/cvat">CVAT</a></li>
<li><a href="https://www.zooniverse.org/">Zooniverse</a></li>
</ul>
<p>An exploding number of start-ups and companies are promising to have solved data labeling and curation once and for all, so this list is not comprehensive. Each tool or platform will have benefits and limitations that should be considered. Sharing insights into using these platforms and tools for generating training data is a potential area for further GLAM collaboration, particularly as setting up some annotation tasks is a non-trivial process. There are substantial advantages to using an open-source tool, but this should not be the sole consideration.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-Lee2020TheNN" class="csl-entry" role="doc-biblioentry">
Lee, B., Jaime Mears, Eileen Jakeway, Meghan M. Ferriter, Chris Adams, Nathan Yarasavage, Deborah Thomas, Kate Zwaard, and Daniel S. Weld. 2020. <span>‚ÄúThe Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.‚Äù</span> <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>For example <a href="https://keras.io/api/preprocessing/image/#image_dataset_from_directory-function">Keras</a>, <a href="https://pytorch.org/vision/stable/datasets.html#imagefolder">Pytorch</a> and <a href="https://docs.fast.ai/vision.data.html#imagedataloaders.from_folder">fastai</a> all support loading image data from this folder structure.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./business_problem.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching ML projects: defining the ‚Äòproblem‚Äô</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
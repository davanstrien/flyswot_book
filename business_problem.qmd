
# Defining the 'business' problem

The British Library has a vast amount of 'legacy' digitised content
stored on network drives. The Heritage Made Digital (HMD) team has been
tasked with making these available for users online. We have multiple
terabytes of image files, mostly containing photos or scans of the items
in our physical collection. One of the viewing platforms that we have
made our manuscript image sets available on over the years is
our[](https://www.bl.uk/manuscripts/Default.aspx)[*Digitised
Manuscripts*](https://www.bl.uk/manuscripts/Default.aspx) (DM) website
so that people can look at and study the digitised versions of the
physical objects without needing to come into one of our buildings in St
Pancras or Boston Spa.

The thing is, DM was never designed to be our primary, strategic,
good-for-all-occasions image viewer. It was built for a specific project
that wanted to publish a limited number of similarly constructed
manuscripts. Namely the [Greek
Manuscripts](https://www.bl.uk/collection-guides/greek-manuscripts)
project.

The physical structure of the items in the Greek Manuscripts project are
largely uniform. They are bound codices (of varying sizes and material
types) and to digitise these all you need to do is take a photo of the
front cover, front flysheets, folios, end flysheets, back cover and
spine. That's six different types of images. Or, in terms of our
standardised filenames (ignoring the r and v we put at the end of
filenames for each recto and verso shot, for the sake of simplicity):

- `fblef` - front cover
- `fs001` - front flysheet
- `f001` - folio
- `fse001` - end flysheet
- `fbrig` - back cover
- `fbspi` - spine

And so DM was built to accommodate these and only these options, with no
room for something physically unusual that didn't fit this standard.

Regardless of this shortcoming, DM was pretty good, and better than
anything else we had at the time, so other projects started using it to
publish their manuscript material. This is where the problem arose.

The material in these other projects wasn't as uniform as the items in
the Greek Manuscripts project, and sometimes we wanted to take images of
fore-edges, or clasps, or bags, or anything else interesting or integral
to the physical item. The only way to publish these images on DM was to
assign them one of the six standard filenames, and the agreed approach
was to call them an end flysheet, and give it a number at the end of the
sequence. In other words, if you already have two end flysheets, the
image filename of the fore-edge will be called fse003. A 'fake'
flysheet.

This worked fine for years, but we are now at the point of moving on
from Digitised Manuscripts and we are beginning to migrate all our
digital content into our new preservation and access system, allowing
people to view and download images from our IIIF-compatible viewer, the
[Universal
Viewer](https://blogs.bl.uk/digital-scholarship/2016/12/new-viewer-digitised-collections-british-library.html).

This new system allows us to display whatever images we want, in any
sequence order, and label them however we want, regardless of the
filename. This gives us an opportunity to correctly relabel images that
were published to DM as 'fake' flysheets, so that users can better
understand the digital objects we're presenting to them.

Unfortunately, however, we kept little to no records of which images we
renamed as 'fake' flysheets. There are potentially hundreds or thousands
of these scattered throughout the tens of thousands of items we've
digitised. Rather than manually checking every image as we migrate it to
the new system we thought it might be more efficient and sustainable to
use an automated or semi-automated computational method to do this task,
or at least get one to help us to do it.

It's worth saying that even though we may have initially dreamed of a
magic program to solve all our problems - identifying all our 'fake'
flysheets with a click of a button and relabelling them for us - we very
quickly downgraded our expectations. The main reason we couldn't put our
faith in a totally automated solution is because we know our collection
(or at least we know how physically varied it can be), how big it is,
and how we don't really know everything about it. Given the myriad of
items we've digitised over the last 20+ years, we were pretty sure a
tool wouldn't be able to pick out all the subtle differences in images
with 100% accuracy - a task even trained humans find difficult to do.
This turned out to be a fairly sensible assumption and what we actually
needed was a tool that could be used as part of our existing migration
workflow, confirming the large majority of images as real flysheets
whilst flagging up images it suspected were fakes, for a human to then
manually confirm or deny by looking at the image.

So the task became one to create a tool as quickly and easily as
possible, that was simple to use and maintain, that fit into our
existing workflow, gave us accurate results, and we felt confident
enough to trust. Because we lacked the required software development
skills within the team, we turned to colleagues with expertise in
machine learning and set up a meeting to outline our requirements; so
the concept for flyswot was born.

A bonus to this whole approach was that we could work more closely with
colleagues we don't necessarily engage with on a day-to-day basis. It
also brought a subset of our team closer together in pursuit of a new
extracurricular activity, and we'd all be able to learn about new tools
and technologies.

